---
title: cheetsheet
date: 2023-08-13 17:14:214
hero_image: ''
lang: zh
duration: 1min
---

## 如何对域名进行提前建联？

http基于tcp，每次请求都要进行建立tcp连接，浏览器的话可以通过 `preconnect`来预建联

```js
<link rel="preconnect" href="https://example.com" />
```
另外还可以通过以下方式来减少连接次数

- 域名收拢。也就是尽量收敛到相同域名
- ip收拢。一个 TCP 连接是由一个四元组组成的（源 IP、源端口、目标 IP、目标端口），和域名无关，所以请求两个域名但是来自同一个ip的时候，会复用链接（dns解析还是有的）


## CDN detector
CDN Detector（内容分发网络检测器）是一种用于检测和识别网站使用的内容分发网络（CDN）的工具或服务。CDN Detector 的主要目的是确定一个网站是否使用了CDN以及具体使用了哪个CDN提供商。

CDN Detector 通过分析网站的请求响应、DNS 解析、HTTP 头等信息，来检测网站是否使用了CDN。它可以根据不同的特征和指标，识别出网站所使用的CDN提供商，如Cloudflare、Akamai、Fastly等。CDN Detector 可以通过自动化的方式进行检测，也可以提供API或在线服务，供用户查询指定网站的CDN信息。

CDN Detector 对于网站管理员和开发人员来说，可以帮助他们了解和分析网站的CDN使用情况，优化网站性能，确保CDN的正确配置和使用。同时，对于安全研究人员和黑客来说，CDN Detector 也可以帮助他们了解和探测目标网站的CDN信息，从而进行更有针对性的攻击和安全评估。

## ACL 隔离 和 路由隔离

### 1. ACL 隔离 (Access Control List Isolation)

**ACL 隔离** 是一种基于“规则”的隔离方法，它工作在网络的**数据平面（Data Plane）**或**转发平面（Forwarding Plane）**。

您可以把它想象成一个设置在网络设备端口上的**“保安”或“门卫”**。

* **核心机制：**
    ACL 是一系列“允许”或“拒绝”的规则。当数据包到达一个配置了 ACL 的设备接口（如路由器或交换机的端口）时，设备会检查数据包的头部信息（如源/目的IP地址、源/目的端口号、协议类型等），然后与 ACL 规则逐条匹配。

    * 如果匹配到一条“允许”规则，数据包就被放行。
    * 如果匹配到一条“拒绝”规则，数据包就被丢弃。
    * 如果没有匹配到任何规则，通常会按照一条隐含的“全部拒绝”规则处理。

* **如何实现隔离：**
    通过精心设计的 ACL 规则，我们可以精确地控制哪些流量可以从一个网络区域（如一个VLAN或子网）流向另一个区域。例如，你可以设置一条规则：
    * `允许` 财务部门（子网A）访问打印服务器（IP地址P）。
    * `拒绝` 财务部门（子网A）访问研发部门（子网B）的任何资源。
    * `拒绝` 所有其他网络访问财务部门（子网A）。

* **特点：**
    * **关注“能不能通”：** ACL 主要决定的是两个点之间是否允许通信。
    * **状态性：** 现代的 ACL（状态化防火墙）可以跟踪连接状态，如果一个连接是从内部发起的，那么返回的流量会被自动允许，这比传统的无状态ACL更安全、更方便。
    * **精细控制：** 可以控制到具体的IP地址、端口和协议级别。
    * **位置：** 通常配置在不同网络区域的边界，如三层交换机或路由器的接口上。

**简单比喻：** ACL 隔离就像是**一栋大楼里的门禁卡系统**。即使所有房间都在同一楼层（网络路由可达），但你的门禁卡（ACL规则）决定了你只能进入你被授权的房间（允许访问的资源）。

---

### 2. 路由隔离 (Route Isolation)

**路由隔离** 是一种更彻底的隔离方法，它工作在网络的**控制平面（Control Plane）**。

您可以把它想象成给不同的租户或部门**提供完全独立的“地图”和“道路系统”**。

* **核心机制：**
    路由隔离通过创建多个独立的、虚拟的路由和转发表实例来实现。最典型的技术就是 **VRF (Virtual Routing and Forwarding)**。
    * 在一个物理路由器上，可以创建多个虚拟路由器（VRF实例）。
    * 每个 VRF 实例都有自己独立的路由表、接口和路由协议进程。
    * 一个 VRF 中的路由信息不会泄露到另一个 VRF 中。

* **如何实现隔离：**
    我们将不同的网络区域（如不同的部门、不同的客户）划分到不同的 VRF 中。
    * 财务部门的所有接口和路由都在“财务VRF”中。
    * 研发部门的所有接口和路由都在“研发VRF”中。
    * 由于这两个 VRF 的路由表是完全独立的，从“财务VRF”的角度看，“研发VRF”的网络根本就是**不可知、不可达**的，反之亦然。它们就像在两个完全不相干的物理网络中一样。

* **特点：**
    * **关注“知不知道路”：** 路由隔离决定的是一个网络区域是否“知道”通往另一个网络区域的路径。如果路由表中没有路，流量根本就不会被转发。
    * **彻底隔离：** 这是从网络拓扑层面实现的隔离，默认情况下，不同 VRF 之间完全不通。如果需要通信，必须通过显式的配置（如路由泄露）来打通。
    * **允许IP地址重叠：** 因为路由表是独立的，所以不同的 VRF 中可以使用相同的IP地址范围而不会产生冲突。这对于多租户环境和云服务商非常重要。
    * **位置：** 通常在需要承载多个独立网络域的骨干或汇聚层设备上配置。

**简单比喻：** 路由隔离就像是**两个国家各自独立的公路系统**。虽然它们可能都在同一片大陆上（同一个物理设备），但A国的地图上完全没有B国的道路信息，因此A国的车辆根本不知道如何开往B国。

---

### 总结对比

| 特性     | ACL 隔离 (Access Control List)                    | 路由隔离 (Route Isolation / VRF)                     |
| :------- | :------------------------------------------------ | :--------------------------------------------------- |
| **工作层面** | **数据平面** (检查已存在的流量)                   | **控制平面** (构建路由路径)                          |
| **隔离原理** | **过滤流量 (Filtering)** - “有路，但设了关卡不让过” | **分离路由 (Segregating Paths)** - “地图上根本没画这条路” |
| **隔离程度** | 较弱，有选择性地隔离                            | 非常强，默认完全隔离                                 |
| **配置复杂度** | 规则多时会很复杂，且容易出错                    | 概念清晰，配置相对直接，扩展性好                     |
| **IP地址重叠** | **不允许** (因为都在同一个路由域中)             | **允许** (因为路由表是独立的)                        |
| **典型场景** | 企业内部部门间访问控制、服务器端口安全            | 多租户环境、云服务商、园区网中需要彻底隔离的不同业务 |

在实际应用中，这两种技术经常结合使用，以构建一个既安全又灵活的网络架构。例如，使用 VRF 实现不同租户的彻底隔离，然后在每个租户自己的 VRF 内部，再使用 ACL 进行更精细的访问控制。

## VIP 如何打破网络隔离

“VIP 申请”（申请和部署一个虚拟IP地址）本身并不会随意“打破”网络隔离，而是为**跨越网络隔离提供了一个可控、安全且专用的“入口”**。它不是把墙推倒，而是在墙上开了一个有严格安检的指定窗口。

这个过程的核心是利用**负载均衡器 (Load Balancer)** 作为中间人。

---

### 用一个比喻来理解

想象一下：
* **一个高度安全的办公区（隔离网络）：** 里面有很多员工（后端真实服务器），他们负责处理各种业务。这个区域有严格的门禁，外人无法随意进入。
* **大楼的大厅（外部网络/用户网络）：** 访客（用户/客户端）在这里活动。
* **前台接待员（负载均衡器 + VIP）：** 接待员有一个公开的工位和电话号码（这就是VIP）。所有访客都知道只能找前台，而不知道具体员工的分机号和位置。

“申请VIP”的过程就相当于设立这个前台接待服务：
1.  访客（客户端）来到大厅，向接待员（VIP）提出一个服务请求（例如，“我要办理A业务”）。
2.  接待员（负载均衡器）知道办理A业务需要找里面的张三、李四或王五（后端服务器池）。
3.  接待员通过内部通道联系其中一位员工（例如张三），将访客的请求转达给他。**注意：访客自己从未进入安全办公区。**
4.  张三处理完业务，把结果交给接待员。
5.  接待员再将结果转交给访客。

在这个过程中，**网络隔离（安全办公区和公共大厅的隔离）并没有被破坏**，访客无法进入安全区乱逛。但通过接待员这个受控的“入口”，访客的特定业务请求得到了处理。

---

### 技术实现原理

下面我们看看技术上是如何实现的：

**场景定义：**
* **后端网络（隔离区）：** 一个独立的VLAN或VRF，例如 `10.10.10.0/24`。里面部署了多台提供相同服务的真实服务器（Real Servers），IP地址分别是 `10.10.10.101`、`10.10.10.102` 等。这个网络被ACL或路由策略严格保护，外部无法直接访问。
* **前端网络（用户区）：** 用户所在的网络，例如 `192.168.1.0/24`。

**“打破”隔离的关键步骤：**

1.  **部署一个“中间人”—— 负载均衡器 (Load Balancer)**
    这个负载均衡器是一个特殊的网络设备（如 F5, Citrix ADC, Nginx，或云上的 ELB/ALB），它被设计成可以同时连接多个网络。它就像一个跨接在两个隔离区域之间的桥梁。
    * 它有一个接口连接到前端网络（用户区）。
    * 它有另一个接口连接到后端网络（隔离区）。

2.  **申请和配置 VIP (Virtual IP)**
    在负载均衡器**面向前端网络的接口上**配置一个IP地址，这个地址就是 VIP。例如，`192.168.1.100`。用户的所有请求都会发往这个VIP地址。

3.  **配置后端服务器池 (Backend Server Pool)**
    在负载均衡器上，创建一个服务器“池”，把后端网络中那几台真实服务器的**私有IP地址**（`10.10.10.101`, `10.10.10.102`）添加进去。

4.  **建立访问策略和流量转发规则**
    这是最关键的一步。负载均衡器上会建立一条规则：
    * “当收到访问 `VIP 192.168.1.100` 的 `TCP 80` 端口的流量时，请将这个流量（经过处理后）转发到后端服务器池中的一台服务器（如 `10.10.10.101`）的 `TCP 80` 端口。”

**数据包的流动过程：**

1.  **客户端 -> VIP：** 客户端发起一个到 `192.168.1.100` (VIP) 的连接请求。
2.  **流量到达负载均衡器：** 负载均衡器接收到这个请求。
3.  **连接代理和转发：** 负载均衡器作为代理，**终止**来自客户端的连接。然后，它从自己的后端接口IP地址**发起一个新的连接**到后端的一台真实服务器（如 `10.10.10.101`）。
4.  **真实服务器响应：** 服务器处理请求，将响应数据包发回给负载均衡器。
5.  **负载均衡器 -> 客户端：** 负载均衡器再将这个响应发回给最初的客户端。

**总结：VIP 如何“打破”隔离**

* **通过一个有权限的中间人：** 负载均衡器是唯一被授权可以同时访问前端和后端网络的设备。
* **代理机制：** 它不是直接路由流量，而是作为代理。客户端只能与VIP通信，永远不会直接接触到后端服务器。
* **受控的端口和服务：** 隔离只在负载均衡器上配置的特定端口和服务上被“打通”（例如TCP 80端口），后端网络的所有其他端口和服务依然是隔离和受保护的。
* **隐藏后端细节：** 后端网络的拓扑、真实服务器的IP地址等信息对外部完全隐藏。

因此，**申请VIP不是一种破坏安全性的行为，而是一种标准、安全地发布（Publish）隔离区内服务的架构模式。** 它在保证后端网络整体隔离性的前提下，为特定的、合法的业务流量开辟了一个高度受控的“绿色通道”。